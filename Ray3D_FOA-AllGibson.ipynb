{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_srir_sofa(\n",
    "    filepath,\n",
    "    rirs,\n",
    "    source_pos,\n",
    "    mic_pos,\n",
    "    db_name=\"Default_db\",\n",
    "    room_name=\"Room_name\",\n",
    "    listener_name=\"foa\",\n",
    "    sr=24000,\n",
    "    comment=\"N/A\",\n",
    "):\n",
    "    print(\"Starting create_srir_sofa function\")\n",
    "    \n",
    "    M = rirs.shape[0]\n",
    "    R = rirs.shape[1]\n",
    "    N = rirs.shape[2]\n",
    "    E = 1\n",
    "    I = 1\n",
    "    C = 3\n",
    "\n",
    "    print(f\"Shapes: M={M}, R={R}, N={N}, E={E}, I={I}, C={C}\")\n",
    "\n",
    "    assert rirs.shape == (M, R, N), f\"RIRs shape mismatch: expected {(M, R, N)}, got {rirs.shape}\"\n",
    "    assert source_pos.shape == (M, C), f\"Source position shape mismatch: expected {(M, C)}, got {source_pos.shape}\"\n",
    "\n",
    "    print(f\"Checking if file exists: {filepath}\")\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Overwriting {filepath}\")\n",
    "        os.remove(filepath)\n",
    "    \n",
    "    print(\"Creating Dataset\")\n",
    "    rootgrp = Dataset(filepath, \"w\", format=\"NETCDF4\")\n",
    "\n",
    "    print(\"Setting Required Attributes\")\n",
    "    rootgrp.Conventions = \"SOFA\"\n",
    "    rootgrp.Version = \"2.1\"\n",
    "    rootgrp.SOFAConventions = \"SingleRoomSRIR\"\n",
    "    rootgrp.SOFAConventionsVersion = \"1.0\"\n",
    "    rootgrp.APIName = \"pysofaconventions\"\n",
    "    rootgrp.APIVersion = \"0.1.5\"\n",
    "    rootgrp.AuthorContact = \"chris.ick@nyu.edu\"\n",
    "    rootgrp.Organization = \"Music and Audio Research Lab - NYU\"\n",
    "    rootgrp.License = \"Use whatever you want\"\n",
    "    rootgrp.DataType = \"FIR\"\n",
    "    rootgrp.DateCreated = time.ctime(time.time())\n",
    "    rootgrp.DateModified = time.ctime(time.time())\n",
    "    rootgrp.Title = db_name + \" - \" + room_name\n",
    "    rootgrp.RoomType = \"shoebox\"\n",
    "    rootgrp.DatabaseName = db_name\n",
    "    rootgrp.ListenerShortName = listener_name\n",
    "    rootgrp.RoomShortName = room_name\n",
    "    rootgrp.Comment = comment\n",
    "\n",
    "    print(\"Creating Required Dimensions\")\n",
    "    rootgrp.createDimension(\"M\", M)\n",
    "    rootgrp.createDimension(\"N\", N)\n",
    "    rootgrp.createDimension(\"E\", E)\n",
    "    rootgrp.createDimension(\"R\", R)\n",
    "    rootgrp.createDimension(\"I\", I)\n",
    "    rootgrp.createDimension(\"C\", C)\n",
    "\n",
    "    print(\"Creating Required Variables\")\n",
    "    print(\"Creating ListenerPosition\")\n",
    "    listenerPositionVar = rootgrp.createVariable(\"ListenerPosition\", \"f8\", (\"M\", \"C\"))\n",
    "    listenerPositionVar.Units = \"metre\"\n",
    "    listenerPositionVar.Type = \"cartesian\"\n",
    "    listenerPositionVar[:] = mic_pos\n",
    "\n",
    "    print(\"Creating ListenerUp\")\n",
    "    listenerUpVar = rootgrp.createVariable(\"ListenerUp\", \"f8\", (\"I\", \"C\"))\n",
    "    listenerUpVar.Units = \"metre\"\n",
    "    listenerUpVar.Type = \"cartesian\"\n",
    "    listenerUpVar[:] = np.asarray([0, 0, 1])\n",
    "\n",
    "    print(\"Creating ListenerView\")\n",
    "    listenerViewVar = rootgrp.createVariable(\"ListenerView\", \"f8\", (\"I\", \"C\"))\n",
    "    listenerViewVar.Units = \"metre\"\n",
    "    listenerViewVar.Type = \"cartesian\"\n",
    "    listenerViewVar[:] = np.asarray([1, 0, 0])\n",
    "\n",
    "    print(\"Creating EmitterPosition\")\n",
    "    emitterPositionVar = rootgrp.createVariable(\n",
    "        \"EmitterPosition\", \"f8\", (\"E\", \"C\", \"I\")\n",
    "    )\n",
    "    emitterPositionVar.Units = \"metre\"\n",
    "    emitterPositionVar.Type = \"spherical\"\n",
    "    emitterPositionVar[:] = np.zeros((E, C, I))\n",
    "\n",
    "    print(\"Creating SourcePosition\")\n",
    "    sourcePositionVar = rootgrp.createVariable(\"SourcePosition\", \"f8\", (\"M\", \"C\"))\n",
    "    sourcePositionVar.Units = \"metre\"\n",
    "    sourcePositionVar.Type = \"cartesian\"\n",
    "    sourcePositionVar[:] = source_pos\n",
    "\n",
    "    print(\"Creating SourceUp\")\n",
    "    sourceUpVar = rootgrp.createVariable(\"SourceUp\", \"f8\", (\"I\", \"C\"))\n",
    "    sourceUpVar.Units = \"metre\"\n",
    "    sourceUpVar.Type = \"cartesian\"\n",
    "    sourceUpVar[:] = np.asarray([0, 0, 1])\n",
    "\n",
    "    print(\"Creating SourceView\")\n",
    "    sourceViewVar = rootgrp.createVariable(\"SourceView\", \"f8\", (\"I\", \"C\"))\n",
    "    sourceViewVar.Units = \"metre\"\n",
    "    sourceViewVar.Type = \"cartesian\"\n",
    "    sourceViewVar[:] = np.asarray([1, 0, 0])\n",
    "\n",
    "    print(\"Creating ReceiverPosition\")\n",
    "    receiverPositionVar = rootgrp.createVariable(\n",
    "        \"ReceiverPosition\", \"f8\", (\"R\", \"C\", \"I\")\n",
    "    )\n",
    "    receiverPositionVar.Units = \"metre\"\n",
    "    receiverPositionVar.Type = \"cartesian\"\n",
    "    receiverPositionVar[:] = np.zeros((R, C, I))\n",
    "\n",
    "    print(\"Creating Data.SamplingRate\")\n",
    "    samplingRateVar = rootgrp.createVariable(\"Data.SamplingRate\", \"f8\", (\"I\"))\n",
    "    samplingRateVar.Units = \"hertz\"\n",
    "    samplingRateVar[:] = sr\n",
    "\n",
    "    print(\"Creating Data.Delay\")\n",
    "    delayVar = rootgrp.createVariable(\"Data.Delay\", \"f8\", (\"I\", \"R\"))\n",
    "    delay = np.zeros((I, R))\n",
    "    delayVar[:, :] = delay\n",
    "\n",
    "    print(\"Creating Data.IR\")\n",
    "    dataIRVar = rootgrp.createVariable(\"Data.IR\", \"f8\", (\"M\", \"R\", \"N\"))\n",
    "    dataIRVar.ChannelOrdering = \"acn\"  # standard ambi ordering\n",
    "    dataIRVar.Normalization = \"sn3d\"\n",
    "    dataIRVar[:] = rirs\n",
    "\n",
    "    print(\"Closing file\")\n",
    "    rootgrp.close()  # Note: Added parentheses here\n",
    "    print(f\"SOFA file saved to {filepath}\")\n",
    "    print(\"create_srir_sofa function completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "import time\n",
    "import trimesh\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import csv \n",
    "from rlr_audio_propagation import Config, Context, ChannelLayout, ChannelLayoutType\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "GIBSON_DB_NAME = \"GIBSON\"\n",
    "DATASET_DIR = \"/datasets/soundspaces/scene_datasets/gibson_copy\"\n",
    "#\"/datasets/soundspaces/scene_datasets/gibson_data/gibson/\"\n",
    "dest_path_sofa = Path(\"/datasets/soundspaces/ss_rooms\")\n",
    "dest_path_sofa.mkdir(parents=True, exist_ok=True)\n",
    "audio_fmts = [\"foa\"]\n",
    "\n",
    "\n",
    "def sofa_file_exists(glb_file, dest_path_sofa, audio_fmts):\n",
    "    for fmt in audio_fmts:\n",
    "        filepath = dest_path_sofa / f\"soundspaces_{fmt}_{os.path.splitext(glb_file.name)[0]}.sofa\"\n",
    "        if filepath.exists():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def prepare_soundspaces(glb_file, dest_path_sofa, audio_fmts=[\"foa\"]):\n",
    "    global source_spheres, cfg, ctx, scene, mic_pos, source_positions, adjusted_source_positions\n",
    "\n",
    "    # Reset the variables\n",
    "    source_spheres = []\n",
    "    cfg = Config()\n",
    "    ctx = Context(cfg)\n",
    "    scene = trimesh.Scene()\n",
    "    mic_pos = None\n",
    "    source_positions = []\n",
    "    adjusted_source_positions = []\n",
    "    \n",
    "    Image.MAX_IMAGE_PIXELS = None\n",
    "    mesh = trimesh.load(glb_file, force='mesh')\n",
    "    \n",
    "    # MESH REPAIR PROCESS \n",
    "    vertices = mesh.vertices.copy()\n",
    "    faces = mesh.faces.copy()\n",
    "    new_mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
    "    broken_faces = trimesh.repair.broken_faces(new_mesh)\n",
    "    print(f\"Number of broken faces: {len(broken_faces)}\")\n",
    "    trimesh.repair.fix_inversion(new_mesh)\n",
    "    trimesh.repair.fix_normals(new_mesh)\n",
    "    trimesh.repair.fix_winding(new_mesh)\n",
    "    new_mesh.fill_holes()\n",
    "    new_mesh.visual.face_colors = np.ones((len(new_mesh.faces), 4)) * 255\n",
    "    new_mesh.visual.face_colors[broken_faces] = [255, 0, 0, 255]\n",
    "    broken_faces = trimesh.repair.broken_faces(new_mesh)\n",
    "    print(f\"Number of broken faces: {len(broken_faces)}\")\n",
    "    \n",
    "    scene = trimesh.Scene()\n",
    "    scene.add_geometry(new_mesh)\n",
    "    \n",
    "    cfg = Config()\n",
    "    \n",
    "    source_spheres = []\n",
    "    \n",
    "    def add_sphere(scene, pos, color=[0,0,0], r=0.2):\n",
    "        sphere = trimesh.creation.uv_sphere(radius=r)\n",
    "        sphere.apply_translation(pos)\n",
    "        sphere.visual.face_colors = color\n",
    "        scene.add_geometry(sphere)\n",
    "        return sphere\n",
    "    \n",
    "    def is_point_inside_mesh(mesh, point):\n",
    "        return mesh.contains([point])[0]\n",
    "    \n",
    "    def get_random_point_inside_mesh(mesh, min_distance_from_surface=0.2):\n",
    "        while True:\n",
    "            point = np.random.uniform(mesh.bounds[0], mesh.bounds[1])\n",
    "            if is_point_inside_mesh(mesh, point):\n",
    "                # Check distance from surface\n",
    "                _, distance, _ = mesh.nearest.on_surface([point])\n",
    "                if distance[0] >= min_distance_from_surface:\n",
    "                    return point\n",
    "    \n",
    "    def calculate_weighted_average_ray_length(mesh, point, num_rays=100):\n",
    "        angles = np.random.uniform(0, 2*np.pi, num_rays)\n",
    "        elevations = np.random.uniform(-np.pi/2, np.pi/2, num_rays)\n",
    "        directions = np.column_stack([\n",
    "            np.cos(elevations) * np.cos(angles),\n",
    "            np.cos(elevations) * np.sin(angles),\n",
    "            np.sin(elevations)\n",
    "        ])\n",
    "        origins = np.tile(point, (num_rays, 1))\n",
    "        distances = trimesh.proximity.longest_ray(mesh, origins, directions)\n",
    "        \n",
    "        # Apply weights to the distances (square the distances)\n",
    "        weights = distances ** 2\n",
    "        \n",
    "        # Calculate weighted average\n",
    "        weighted_average = np.sum(distances * weights) / np.sum(weights)\n",
    "        \n",
    "        return weighted_average\n",
    "    \n",
    "    # Find a suitable microphone position\n",
    "    min_avg_ray_length = 3.0  # we can adjust this value as needed \n",
    "    max_attempts = 100\n",
    "    for attempt in range(max_attempts):\n",
    "        mic_pos = get_random_point_inside_mesh(new_mesh)\n",
    "        avg_ray_length = calculate_weighted_average_ray_length(new_mesh, mic_pos)\n",
    "        \n",
    "        if avg_ray_length >= min_avg_ray_length:\n",
    "            print(f\"Found suitable microphone position after {attempt+1} attempts\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Could not find a suitable position after {max_attempts} attempts. Using the last attempted position.\")\n",
    "    \n",
    "    add_sphere(scene, mic_pos, [255, 0, 0]) # MICROPHONE IS PLACED! \n",
    "    \n",
    "    ctx = Context(cfg)\n",
    "    ctx.add_object()\n",
    "    ctx.set_object_position(0, [0, 0, 0])\n",
    "    ctx.add_mesh_vertices(new_mesh.vertices.flatten().tolist())\n",
    "    ctx.add_mesh_indices(new_mesh.faces.flatten().tolist(), 3, \"default\")\n",
    "    ctx.finalize_object_mesh(0)\n",
    "    \n",
    "    # Add listener (microphone)\n",
    "    ctx.add_listener(ChannelLayout(ChannelLayoutType.Ambisonics, 4))\n",
    "    ctx.set_listener_position(0, mic_pos.tolist())\n",
    "    \n",
    "    # First sample a large number of evenly spaced angles\n",
    "    num_initial_rays = 200 #1500 \n",
    "    initial_angles = np.linspace(0, 2*np.pi, num_initial_rays, endpoint=False)\n",
    "    initial_ray_directions = np.column_stack((np.cos(initial_angles), np.sin(initial_angles), np.zeros_like(initial_angles)))\n",
    "    \n",
    "    # Get distances for these initial rays\n",
    "    ray_origins = np.tile(mic_pos, (num_initial_rays, 1))\n",
    "    distances = trimesh.proximity.longest_ray(new_mesh, ray_origins, initial_ray_directions)\n",
    "    \n",
    "    max_distance = 10.0\n",
    "    distances = np.minimum(distances, max_distance)\n",
    "    \n",
    "    # Calculate the number of rays to keep based on distances\n",
    "    num_rays_to_keep = 100 #1000 \n",
    "    probabilities = distances / np.sum(distances) # longer distances get higher probabilities\n",
    "    selected_indices = np.random.choice(num_initial_rays, size=num_rays_to_keep, replace=False, p=probabilities)\n",
    "    \n",
    "    # Sort the selected indices to maintain the order\n",
    "    selected_indices.sort()\n",
    "    \n",
    "    # Only use the selected rays\n",
    "    ray_directions = initial_ray_directions[selected_indices]\n",
    "    distances = distances[selected_indices]\n",
    "    \n",
    "    for i, direction in enumerate(ray_directions):\n",
    "        ray_end = mic_pos + direction * distances[i]\n",
    "        ray_points = np.vstack((mic_pos, ray_end))\n",
    "        ray_path = trimesh.load_path(ray_points)\n",
    "        scene.add_geometry(ray_path)\n",
    "    \n",
    "    # Sample points along the rays\n",
    "    num_sources = 1000 \n",
    "    d = distances**2  # squaring makes it more likely to choose longer rays to sample from \n",
    "    idx_rays = np.random.choice(np.arange(len(distances)), size=num_sources, replace=True, p=d/d.sum())\n",
    "    dist_proportion = np.sqrt(np.random.uniform(0, 1, size=num_sources))\n",
    "    source_dist = distances[idx_rays] * dist_proportion\n",
    "    \n",
    "    min_distance = 0.2 \n",
    "    min_distance_from_mic = 0.1 \n",
    "    source_positions = []\n",
    "    for i, idx in enumerate(idx_rays):\n",
    "        attempts = 0\n",
    "        while attempts < 10: \n",
    "            new_pos = mic_pos + ray_directions[idx] * source_dist[i]\n",
    "            if (not source_positions or all(np.linalg.norm(new_pos - pos) >= min_distance for pos in source_positions)) and np.linalg.norm(new_pos - mic_pos) >= min_distance_from_mic:\n",
    "        # Place the source\n",
    "                source_positions.append(new_pos)\n",
    "                sphere = add_sphere(scene, new_pos, [0, 0, 255], r=0.05)\n",
    "                source_spheres.append(sphere)\n",
    "                break\n",
    "            else:\n",
    "                source_dist[i] = distances[idx] * np.sqrt(np.random.uniform(0, 1))\n",
    "            attempts += 1\n",
    "    \n",
    "    # Add sources\n",
    "    for i, position in enumerate(source_positions):\n",
    "        ctx.add_source()\n",
    "        ctx.set_source_position(i, position.tolist())\n",
    "    \n",
    "    def adjust_source_elevation(mesh, position):\n",
    "        # Calculate the total height of the mesh\n",
    "        mesh_height = mesh.bounds[1][2] - mesh.bounds[0][2]\n",
    "        \n",
    "        # Set max_elevation_change to half of the mesh height\n",
    "        max_elevation_change = mesh_height / 2\n",
    "    \n",
    "        elevation_change = np.random.uniform(-max_elevation_change, max_elevation_change)\n",
    "        elevation_vector = np.array([0, 0, elevation_change])\n",
    "        new_position = position + elevation_vector\n",
    "        \n",
    "        if is_point_inside_mesh(mesh, new_position):\n",
    "            return new_position\n",
    "        else:\n",
    "            # If outside, try to find valid position within the mesh\n",
    "            for _ in range(10):  # Try up to 10 times\n",
    "                elevation_change = np.random.uniform(-max_elevation_change, max_elevation_change)\n",
    "                elevation_vector = np.array([0, 0, elevation_change])\n",
    "                new_position = position + elevation_vector\n",
    "                if is_point_inside_mesh(mesh, new_position):\n",
    "                    return new_position\n",
    "            # If we couldn't find valid position, return the original\n",
    "            return position\n",
    "    \n",
    "    # Adjust elevations of source positions\n",
    "    adjusted_source_positions = []\n",
    "    for i, position in enumerate(source_positions):\n",
    "        new_position = adjust_source_elevation(new_mesh, position)\n",
    "        adjusted_source_positions.append(new_position)\n",
    "        \n",
    "        # Update the sphere in the scene\n",
    "        source_spheres[i].apply_translation(new_position - position)\n",
    "        # Update source position in the simulation context\n",
    "        ctx.set_source_position(i, new_position.tolist())\n",
    "    \n",
    "    # Replace the original source_positions with the adjusted ones\n",
    "    source_positions = adjusted_source_positions\n",
    "    \n",
    "    print(f\"Adjusted {len(source_positions)} source positions for elevation\")\n",
    "    \n",
    "    # Run simulation\n",
    "    ctx.simulate()\n",
    "    efficiency = ctx.get_indirect_ray_efficiency()\n",
    "    print(f\"Overall Indirect Ray Efficiency = {efficiency}\")\n",
    "    scene.show()\n",
    "\n",
    "    # Generate and save the plots\n",
    "    room_name = os.path.splitext(os.path.basename(glb_file))[0]\n",
    "    \n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # Top-down view\n",
    "    vertices = new_mesh.vertices\n",
    "    ax1.scatter(vertices[:, 0], vertices[:, 1], c='gray', alpha=0.1, s=1)\n",
    "    ax1.scatter(mic_pos[0], mic_pos[1], c='red', s=100, label='Microphone')\n",
    "    new_sources = np.array(source_positions)\n",
    "    ax1.scatter(new_sources[:, 0], new_sources[:, 1], c='blue', s=25, alpha=0.5, label='Sound Sources')\n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_title(f'Top-down view of {room_name}')\n",
    "    ax1.legend()\n",
    "    ax1.axis('equal')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Side view\n",
    "    ax2.scatter(vertices[:, 0], vertices[:, 2], c='gray', alpha=0.1, s=1)  # X vs Z\n",
    "    ax2.scatter(mic_pos[0], mic_pos[2], c='red', s=100, label='Microphone')\n",
    "    ax2.scatter(new_sources[:, 0], new_sources[:, 2], c='blue', s=25, alpha=0.5, label='Sound Sources')\n",
    "    ax2.set_xlabel('X')\n",
    "    ax2.set_ylabel('Z')\n",
    "    ax2.set_title(f'Side view of {room_name}')\n",
    "    ax2.legend()\n",
    "    ax2.axis('equal')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = dest_path_sofa / f\"{room_name}_plots.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()  # Close the figure to free up memory\n",
    "\n",
    "    print(f\"Plots saved as {plot_path}\")\n",
    "\n",
    "    # Prepare SOFA file\n",
    "    prepare_sofa(cfg, ctx, source_positions, mic_pos, 0, dest_path_sofa, audio_fmts)\n",
    "\n",
    "\n",
    "def prepare_sofa(cfg, ctx, source_positions, mic_pos, listener_index, dest_path_sofa, audio_fmts=[\"foa\"]):\n",
    "    sr = int(cfg.sample_rate)\n",
    "    print(f\"Total number of source positions: {len(source_positions)}\")\n",
    "\n",
    "    # Create a CSV file for the room\n",
    "    room_name = os.path.splitext(glb_file.name)[0]\n",
    "    csv_filepath = dest_path_sofa / f\"{room_name}_relative_positions.csv\"\n",
    "\n",
    "    with open(csv_filepath, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['Source_Index', 'X', 'Y', 'Z'])  # Write header\n",
    "\n",
    "        for fmt in audio_fmts:\n",
    "            filepath = dest_path_sofa / f\"soundspaces_{fmt}_{os.path.splitext(glb_file.name)[0]}.sofa\"\n",
    "            if filepath.exists():\n",
    "                print(f\"Skipping {fmt} format - SOFA file already exists\")\n",
    "                continue\n",
    "            IRs = []\n",
    "            coords = []\n",
    "            max_length = 0\n",
    "            for source_index, source_position in enumerate(source_positions):\n",
    "                relative_position = np.array(source_position) - np.array(mic_pos)\n",
    "                x, y, z = relative_position\n",
    "                x, y, z = round(x, 3), round(y, 3), round(z, 3)\n",
    "                coords.append([x, y, z])  \n",
    "\n",
    "                # Write relative position to CSV\n",
    "                csv_writer.writerow([source_index, x, y, z])\n",
    "                \n",
    "                ir_sample_count = ctx.get_ir_sample_count(listener_index, source_index)\n",
    "                ir_channel_count = ctx.get_ir_channel_count(listener_index, source_index)\n",
    "                \n",
    "                ir = np.zeros((ir_channel_count, ir_sample_count))\n",
    "                for i in range(ir_channel_count):\n",
    "                    channel = np.array(ctx.get_ir_channel(listener_index, source_index, i))\n",
    "                    ir[i] = channel\n",
    "                if ir.shape[1] > max_length:\n",
    "                    max_length = ir.shape[1]\n",
    "                IRs.append(ir)\n",
    "                \n",
    "                print(f\"IR {source_index}:\")\n",
    "                print(f\"  Position: ({x}, {y}, {z})\")\n",
    "                print(f\"  Channels: {ir_channel_count}\")\n",
    "                print(f\"  Samples: {ir_sample_count}\")\n",
    "                print(f\"  Shape: {ir.shape}\")\n",
    "                print()\n",
    "\n",
    "            # Pad IRs to max_length\n",
    "            padded_IRs = []\n",
    "            for ir in IRs:\n",
    "                if ir.shape[1] < max_length:\n",
    "                    padded = np.zeros((ir.shape[0], max_length))\n",
    "                    padded[:, :ir.shape[1]] = ir\n",
    "                    padded_IRs.append(padded)\n",
    "                else:\n",
    "                    padded_IRs.append(ir[:, :max_length])\n",
    "            \n",
    "            filepath = dest_path_sofa / f\"soundspaces_{fmt}_{os.path.splitext(glb_file.name)[0]}.sofa\"\n",
    "            rirs = np.array(padded_IRs)\n",
    "            source_pos = np.array(coords) \n",
    "            mic_pos = np.array([[0, 0, 0]])\n",
    "            \n",
    "            create_srir_sofa(\n",
    "                filepath,\n",
    "                rirs,\n",
    "                source_pos,\n",
    "                mic_pos,\n",
    "                db_name=GIBSON_DB_NAME,\n",
    "                room_name=\"soundspaces_foa_{os.path.splitext(glb_file.name)[0]}\",\n",
    "                listener_name=\"foa\",\n",
    "                sr=sr,\n",
    "            )\n",
    "\n",
    "    print(f\"Relative positions have been written to {csv_filepath}\")\n",
    "    print(\"SOFA file has been created.\")\n",
    "    print(f\"Final IR array shape: {rirs.shape}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_dir = Path(DATASET_DIR)\n",
    "    for glb_file in dataset_dir.glob(\"*.glb\"):\n",
    "        if sofa_file_exists(glb_file, dest_path_sofa, audio_fmts):\n",
    "            print(f\"Skipping {glb_file.name} - SOFA file already exists\")\n",
    "            continue\n",
    "        print(f\"Processing {glb_file.name}\")\n",
    "        prepare_soundspaces(str(glb_file), dest_path_sofa)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
