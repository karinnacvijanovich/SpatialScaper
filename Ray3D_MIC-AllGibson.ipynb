{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_srir_sofa(\n",
    "    filepath,\n",
    "    rirs,\n",
    "    source_pos,\n",
    "    mic_pos,\n",
    "    db_name=\"Default_db\",\n",
    "    room_name=\"Room_name\",\n",
    "    listener_name=\"mic\",\n",
    "    sr=24000,\n",
    "    comment=\"N/A\",\n",
    "):\n",
    "    print(\"Starting create_srir_sofa function\")\n",
    "    \n",
    "    M = rirs.shape[0]\n",
    "    R = rirs.shape[1]\n",
    "    N = rirs.shape[2]\n",
    "    E = 1\n",
    "    I = 1\n",
    "    C = 3\n",
    "\n",
    "    print(f\"Shapes: M={M}, R={R}, N={N}, E={E}, I={I}, C={C}\")\n",
    "\n",
    "    assert rirs.shape == (M, R, N), f\"RIRs shape mismatch: expected {(M, R, N)}, got {rirs.shape}\"\n",
    "    assert source_pos.shape == (M, C), f\"Source position shape mismatch: expected {(M, C)}, got {source_pos.shape}\"\n",
    "\n",
    "    print(f\"Checking if file exists: {filepath}\")\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Overwriting {filepath}\")\n",
    "        os.remove(filepath)\n",
    "    \n",
    "    print(\"Creating Dataset\")\n",
    "    rootgrp = Dataset(filepath, \"w\", format=\"NETCDF4\")\n",
    "\n",
    "    print(\"Setting Required Attributes\")\n",
    "    rootgrp.Conventions = \"SOFA\"\n",
    "    rootgrp.Version = \"2.1\"\n",
    "    rootgrp.SOFAConventions = \"SingleRoomSRIR\"\n",
    "    rootgrp.SOFAConventionsVersion = \"1.0\"\n",
    "    rootgrp.APIName = \"pysofaconventions\"\n",
    "    rootgrp.APIVersion = \"0.1.5\"\n",
    "    rootgrp.AuthorContact = \"chris.ick@nyu.edu\"\n",
    "    rootgrp.Organization = \"Music and Audio Research Lab - NYU\"\n",
    "    rootgrp.License = \"Use whatever you want\"\n",
    "    rootgrp.DataType = \"FIR\"\n",
    "    rootgrp.DateCreated = time.ctime(time.time())\n",
    "    rootgrp.DateModified = time.ctime(time.time())\n",
    "    rootgrp.Title = db_name + \" - \" + room_name\n",
    "    rootgrp.RoomType = \"shoebox\"\n",
    "    rootgrp.DatabaseName = db_name\n",
    "    rootgrp.ListenerShortName = listener_name\n",
    "    rootgrp.RoomShortName = room_name\n",
    "    rootgrp.Comment = comment\n",
    "\n",
    "    print(\"Creating Required Dimensions\")\n",
    "    rootgrp.createDimension(\"M\", M)\n",
    "    rootgrp.createDimension(\"N\", N)\n",
    "    rootgrp.createDimension(\"E\", E)\n",
    "    rootgrp.createDimension(\"R\", R)\n",
    "    rootgrp.createDimension(\"I\", I)\n",
    "    rootgrp.createDimension(\"C\", C)\n",
    "\n",
    "    print(\"Creating Required Variables\")\n",
    "    print(\"Creating ListenerPosition\")\n",
    "    listenerPositionVar = rootgrp.createVariable(\"ListenerPosition\", \"f8\", (\"M\", \"C\"))\n",
    "    listenerPositionVar.Units = \"metre\"\n",
    "    listenerPositionVar.Type = \"cartesian\"\n",
    "    listenerPositionVar[:] = mic_pos\n",
    "\n",
    "    print(\"Creating ListenerUp\")\n",
    "    listenerUpVar = rootgrp.createVariable(\"ListenerUp\", \"f8\", (\"I\", \"C\"))\n",
    "    listenerUpVar.Units = \"metre\"\n",
    "    listenerUpVar.Type = \"cartesian\"\n",
    "    listenerUpVar[:] = np.asarray([0, 0, 1])\n",
    "\n",
    "    print(\"Creating ListenerView\")\n",
    "    listenerViewVar = rootgrp.createVariable(\"ListenerView\", \"f8\", (\"I\", \"C\"))\n",
    "    listenerViewVar.Units = \"metre\"\n",
    "    listenerViewVar.Type = \"cartesian\"\n",
    "    listenerViewVar[:] = np.asarray([1, 0, 0])\n",
    "\n",
    "    print(\"Creating EmitterPosition\")\n",
    "    emitterPositionVar = rootgrp.createVariable(\n",
    "        \"EmitterPosition\", \"f8\", (\"E\", \"C\", \"I\")\n",
    "    )\n",
    "    emitterPositionVar.Units = \"metre\"\n",
    "    emitterPositionVar.Type = \"spherical\"\n",
    "    emitterPositionVar[:] = np.zeros((E, C, I))\n",
    "\n",
    "    print(\"Creating SourcePosition\")\n",
    "    sourcePositionVar = rootgrp.createVariable(\"SourcePosition\", \"f8\", (\"M\", \"C\"))\n",
    "    sourcePositionVar.Units = \"metre\"\n",
    "    sourcePositionVar.Type = \"cartesian\"\n",
    "    sourcePositionVar[:] = source_pos\n",
    "\n",
    "    print(\"Creating SourceUp\")\n",
    "    sourceUpVar = rootgrp.createVariable(\"SourceUp\", \"f8\", (\"I\", \"C\"))\n",
    "    sourceUpVar.Units = \"metre\"\n",
    "    sourceUpVar.Type = \"cartesian\"\n",
    "    sourceUpVar[:] = np.asarray([0, 0, 1])\n",
    "\n",
    "    print(\"Creating SourceView\")\n",
    "    sourceViewVar = rootgrp.createVariable(\"SourceView\", \"f8\", (\"I\", \"C\"))\n",
    "    sourceViewVar.Units = \"metre\"\n",
    "    sourceViewVar.Type = \"cartesian\"\n",
    "    sourceViewVar[:] = np.asarray([1, 0, 0])\n",
    "\n",
    "    print(\"Creating ReceiverPosition\")\n",
    "    receiverPositionVar = rootgrp.createVariable(\n",
    "        \"ReceiverPosition\", \"f8\", (\"R\", \"C\", \"I\")\n",
    "    )\n",
    "    receiverPositionVar.Units = \"metre\"\n",
    "    receiverPositionVar.Type = \"cartesian\"\n",
    "    receiverPositionVar[:] = np.zeros((R, C, I))\n",
    "\n",
    "    print(\"Creating Data.SamplingRate\")\n",
    "    samplingRateVar = rootgrp.createVariable(\"Data.SamplingRate\", \"f8\", (\"I\"))\n",
    "    samplingRateVar.Units = \"hertz\"\n",
    "    samplingRateVar[:] = sr\n",
    "\n",
    "    print(\"Creating Data.Delay\")\n",
    "    delayVar = rootgrp.createVariable(\"Data.Delay\", \"f8\", (\"I\", \"R\"))\n",
    "    delay = np.zeros((I, R))\n",
    "    delayVar[:, :] = delay\n",
    "\n",
    "    print(\"Creating Data.IR\")\n",
    "    dataIRVar = rootgrp.createVariable(\"Data.IR\", \"f8\", (\"M\", \"R\", \"N\"))\n",
    "    dataIRVar.ChannelOrdering = \"acn\"  # standard ambi ordering\n",
    "    dataIRVar.Normalization = \"sn3d\"\n",
    "    dataIRVar[:] = rirs\n",
    "\n",
    "    print(\"Closing file\")\n",
    "    rootgrp.close()  # Note: Added parentheses here\n",
    "    print(f\"SOFA file saved to {filepath}\")\n",
    "    print(\"create_srir_sofa function completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "import time\n",
    "import trimesh\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import csv \n",
    "from rlr_audio_propagation import Config, Context, ChannelLayout, ChannelLayoutType\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "GIBSON_DB_NAME = \"GIBSON\"\n",
    "DATASET_DIR = \"/datasets/soundspaces/scene_datasets/gibson_copy\"\n",
    "dest_path_sofa = Path(\"/datasets/soundspaces/ss_rooms_tetra\")\n",
    "dest_path_sofa.mkdir(parents=True, exist_ok=True)\n",
    "audio_fmts = [\"mic\"]\n",
    "\n",
    "\n",
    "def sofa_file_exists(glb_file, dest_path_sofa, audio_fmts):\n",
    "    for fmt in audio_fmts:\n",
    "        filepath = dest_path_sofa / f\"soundspaces_{fmt}_{os.path.splitext(glb_file.name)[0]}.sofa\"\n",
    "        if filepath.exists():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def prepare_soundspaces(glb_file, dest_path_sofa, audio_fmts=[\"mic\"]):\n",
    "    global source_spheres, cfg, ctx, scene, mic_positions, source_positions, adjusted_source_positions\n",
    "\n",
    "    # Reset the variables\n",
    "    source_spheres = []\n",
    "    cfg = Config()\n",
    "    ctx = Context(cfg)\n",
    "    scene = trimesh.Scene()\n",
    "    mic_positions = []\n",
    "    source_positions = []\n",
    "    adjusted_source_positions = []\n",
    "    \n",
    "    Image.MAX_IMAGE_PIXELS = None\n",
    "    mesh = trimesh.load(glb_file, force='mesh')\n",
    "    \n",
    "    # MESH REPAIR PROCESS \n",
    "    vertices = mesh.vertices.copy()\n",
    "    faces = mesh.faces.copy()\n",
    "    new_mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
    "    broken_faces = trimesh.repair.broken_faces(new_mesh)\n",
    "    print(f\"Number of broken faces: {len(broken_faces)}\")\n",
    "    trimesh.repair.fix_inversion(new_mesh)\n",
    "    trimesh.repair.fix_normals(new_mesh)\n",
    "    trimesh.repair.fix_winding(new_mesh)\n",
    "    new_mesh.fill_holes()\n",
    "    new_mesh.visual.face_colors = np.ones((len(new_mesh.faces), 4)) * 255\n",
    "    new_mesh.visual.face_colors[broken_faces] = [255, 0, 0, 255]\n",
    "    broken_faces = trimesh.repair.broken_faces(new_mesh)\n",
    "    print(f\"Number of broken faces: {len(broken_faces)}\")\n",
    "    \n",
    "    scene = trimesh.Scene()\n",
    "    scene.add_geometry(new_mesh)\n",
    "    \n",
    "    cfg = Config()\n",
    "    \n",
    "    source_spheres = []\n",
    "    \n",
    "    def add_sphere(scene, pos, color=[0,0,0], r=0.2):\n",
    "        sphere = trimesh.creation.uv_sphere(radius=r)\n",
    "        sphere.apply_translation(pos)\n",
    "        sphere.visual.face_colors = color\n",
    "        scene.add_geometry(sphere)\n",
    "        return sphere\n",
    "    \n",
    "    def is_point_inside_mesh(mesh, point):\n",
    "        return mesh.contains([point])[0]\n",
    "    \n",
    "    def get_random_point_inside_mesh(mesh, min_distance_from_surface=0.2):\n",
    "        while True:\n",
    "            point = np.random.uniform(mesh.bounds[0], mesh.bounds[1])\n",
    "            if is_point_inside_mesh(mesh, point):\n",
    "                # Check distance from surface\n",
    "                _, distance, _ = mesh.nearest.on_surface([point])\n",
    "                if distance[0] >= min_distance_from_surface:\n",
    "                    return point\n",
    "    \n",
    "    def calculate_weighted_average_ray_length(mesh, point, num_rays=100):\n",
    "        angles = np.random.uniform(0, 2*np.pi, num_rays)\n",
    "        elevations = np.random.uniform(-np.pi/2, np.pi/2, num_rays)\n",
    "        directions = np.column_stack([\n",
    "            np.cos(elevations) * np.cos(angles),\n",
    "            np.cos(elevations) * np.sin(angles),\n",
    "            np.sin(elevations)\n",
    "        ])\n",
    "        origins = np.tile(point, (num_rays, 1))\n",
    "        distances = trimesh.proximity.longest_ray(mesh, origins, directions)\n",
    "        \n",
    "        # Apply weights to the distances (square the distances)\n",
    "        weights = distances ** 2\n",
    "        \n",
    "        # Calculate weighted average\n",
    "        weighted_average = np.sum(distances * weights) / np.sum(weights)\n",
    "        \n",
    "        return weighted_average\n",
    "    \n",
    "    # Find a suitable microphone position\n",
    "    min_avg_ray_length = 3.0  # we can adjust this value as needed \n",
    "    max_attempts = 100\n",
    "    for attempt in range(max_attempts):\n",
    "        mic_center = get_random_point_inside_mesh(new_mesh)\n",
    "        avg_ray_length = calculate_weighted_average_ray_length(new_mesh, mic_center)\n",
    "        \n",
    "        if avg_ray_length >= min_avg_ray_length:\n",
    "            print(f\"Found suitable microphone position after {attempt+1} attempts\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Could not find a suitable position after {max_attempts} attempts. Using the last attempted position.\")\n",
    "\n",
    "    mic_radius = 0.06\n",
    "    mic_positions = [\n",
    "        (55, 45),\n",
    "        (125, 315),\n",
    "        (125, 135),\n",
    "        (55, 225)\n",
    "    ]\n",
    "    \n",
    "    def spherical_to_cartesian(r, theta, phi):\n",
    "        theta_rad = np.radians(theta)\n",
    "        phi_rad = np.radians(phi)\n",
    "        x = r * np.sin(theta_rad) * np.cos(phi_rad)\n",
    "        y = r * np.sin(theta_rad) * np.sin(phi_rad)\n",
    "        z = r * np.cos(theta_rad)\n",
    "        return x, y, z\n",
    "    \n",
    "    mic_cartesian = [spherical_to_cartesian(mic_radius, theta, phi) for theta, phi in mic_positions]\n",
    "    mic_absolute_positions = [mic_center + np.array(pos) for pos in mic_cartesian]\n",
    "    \n",
    "    # Add microphone spheres to the scene\n",
    "    for mic_pos in mic_absolute_positions:\n",
    "        add_sphere(scene, mic_pos, [255, 0, 0], r=0.02)  # Red color for microphones\n",
    "\n",
    "    ctx = Context(cfg)\n",
    "    ctx.add_object()\n",
    "    ctx.set_object_position(0, [0, 0, 0])\n",
    "    ctx.add_mesh_vertices(new_mesh.vertices.flatten().tolist())\n",
    "    ctx.add_mesh_indices(new_mesh.faces.flatten().tolist(), 3, \"default\")\n",
    "    ctx.finalize_object_mesh(0)\n",
    "    \n",
    "    # Add listeners (microphones)\n",
    "    for i, mic_pos in enumerate(mic_absolute_positions):\n",
    "        ctx.add_listener(ChannelLayout(ChannelLayoutType.Mono, 1))\n",
    "        ctx.set_listener_position(i, mic_pos.tolist())\n",
    "    \n",
    "    # First sample a large number of evenly spaced angles\n",
    "    num_initial_rays = 200 #1500 \n",
    "    initial_angles = np.linspace(0, 2*np.pi, num_initial_rays, endpoint=False)\n",
    "    initial_ray_directions = np.column_stack((np.cos(initial_angles), np.sin(initial_angles), np.zeros_like(initial_angles)))\n",
    "    \n",
    "    # Get distances for these initial rays\n",
    "    ray_origins = np.tile(mic_center, (num_initial_rays, 1))\n",
    "    distances = trimesh.proximity.longest_ray(new_mesh, ray_origins, initial_ray_directions)\n",
    "    \n",
    "    max_distance = 10.0\n",
    "    distances = np.minimum(distances, max_distance)\n",
    "    \n",
    "    # Calculate the number of rays to keep based on distances\n",
    "    num_rays_to_keep = 100 #1000 \n",
    "    probabilities = distances / np.sum(distances) # longer distances get higher probabilities\n",
    "    selected_indices = np.random.choice(num_initial_rays, size=num_rays_to_keep, replace=False, p=probabilities)\n",
    "    \n",
    "    # Sort the selected indices to maintain the order\n",
    "    selected_indices.sort()\n",
    "    \n",
    "    # Only use the selected rays\n",
    "    ray_directions = initial_ray_directions[selected_indices]\n",
    "    distances = distances[selected_indices]\n",
    "    \n",
    "    for i, direction in enumerate(ray_directions):\n",
    "        ray_end = mic_center + direction * distances[i]\n",
    "        ray_points = np.vstack((mic_center, ray_end))\n",
    "        ray_path = trimesh.load_path(ray_points)\n",
    "        scene.add_geometry(ray_path)\n",
    "    \n",
    "    # Sample points along the rays\n",
    "    num_sources = 1000 \n",
    "    d = distances**2  # squaring makes it more likely to choose longer rays to sample from \n",
    "    idx_rays = np.random.choice(np.arange(len(distances)), size=num_sources, replace=True, p=d/d.sum())\n",
    "    dist_proportion = np.sqrt(np.random.uniform(0, 1, size=num_sources))\n",
    "    source_dist = distances[idx_rays] * dist_proportion\n",
    "    \n",
    "    min_distance = 0.2 \n",
    "    min_distance_from_mic = 0.1 \n",
    "    source_positions = []\n",
    "    for i, idx in enumerate(idx_rays):\n",
    "        attempts = 0\n",
    "        while attempts < 10: \n",
    "            new_pos = mic_center + ray_directions[idx] * source_dist[i]\n",
    "            if (not source_positions or all(np.linalg.norm(new_pos - pos) >= min_distance for pos in source_positions)) and all(np.linalg.norm(new_pos - mic_pos) >= min_distance_from_mic for mic_pos in mic_absolute_positions):\n",
    "                source_positions.append(new_pos)\n",
    "                sphere = add_sphere(scene, new_pos, [0, 0, 255], r=0.05)\n",
    "                source_spheres.append(sphere)\n",
    "                break\n",
    "            else:\n",
    "                source_dist[i] = distances[idx] * np.sqrt(np.random.uniform(0, 1))\n",
    "            attempts += 1\n",
    "    \n",
    "    # Add sources\n",
    "    for i, position in enumerate(source_positions):\n",
    "        ctx.add_source()\n",
    "        ctx.set_source_position(i, position.tolist())\n",
    "    \n",
    "    def adjust_source_elevation(mesh, position):\n",
    "        # Calculate the total height of the mesh\n",
    "        mesh_height = mesh.bounds[1][2] - mesh.bounds[0][2]\n",
    "        max_elevation_change = mesh_height / 2\n",
    "    \n",
    "        elevation_change = np.random.uniform(-max_elevation_change, max_elevation_change)\n",
    "        elevation_vector = np.array([0, 0, elevation_change])\n",
    "        new_position = position + elevation_vector\n",
    "        \n",
    "        if is_point_inside_mesh(mesh, new_position):\n",
    "            return new_position\n",
    "        else:\n",
    "            # If outside, try to find valid position within the mesh\n",
    "            for _ in range(10):  # Try up to 10 times\n",
    "                elevation_change = np.random.uniform(-max_elevation_change, max_elevation_change)\n",
    "                elevation_vector = np.array([0, 0, elevation_change])\n",
    "                new_position = position + elevation_vector\n",
    "                if is_point_inside_mesh(mesh, new_position):\n",
    "                    return new_position\n",
    "            # If we couldn't find valid position, return the original\n",
    "            return position\n",
    "    \n",
    "    # Adjust elevations of source positions\n",
    "    adjusted_source_positions = []\n",
    "    for i, position in enumerate(source_positions):\n",
    "        new_position = adjust_source_elevation(new_mesh, position)\n",
    "        adjusted_source_positions.append(new_position)\n",
    "        \n",
    "        # Update the sphere in the scene\n",
    "        source_spheres[i].apply_translation(new_position - position)\n",
    "        # Update source position in the simulation context\n",
    "        ctx.set_source_position(i, new_position.tolist())\n",
    "    \n",
    "    # Replace the original source_positions with the adjusted ones\n",
    "    source_positions = adjusted_source_positions\n",
    "    \n",
    "    print(f\"Adjusted {len(source_positions)} source positions for elevation\")\n",
    "    \n",
    "    # Run simulation\n",
    "    ctx.simulate()\n",
    "    efficiency = ctx.get_indirect_ray_efficiency()\n",
    "    print(f\"Overall Indirect Ray Efficiency = {efficiency}\")\n",
    "    scene.show()\n",
    "\n",
    "    # Generate and save the plots\n",
    "    room_name = os.path.splitext(os.path.basename(glb_file))[0]\n",
    "    \n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # Top-down view\n",
    "    vertices = new_mesh.vertices\n",
    "    ax1.scatter(vertices[:, 0], vertices[:, 1], c='gray', alpha=0.1, s=1)\n",
    "    ax1.scatter(mic_center[0], mic_center[1], c='red', s=100, label='Microphone')\n",
    "    new_sources = np.array(source_positions)\n",
    "    ax1.scatter(new_sources[:, 0], new_sources[:, 1], c='blue', s=25, alpha=0.5, label='Sound Sources')\n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_title(f'Top-down view of {room_name}')\n",
    "    ax1.legend()\n",
    "    ax1.axis('equal')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Side view\n",
    "    ax2.scatter(vertices[:, 0], vertices[:, 2], c='gray', alpha=0.1, s=1)  # X vs Z\n",
    "    ax2.scatter(mic_center[0], mic_center[2], c='red', s=100, label='Microphone')\n",
    "    ax2.scatter(new_sources[:, 0], new_sources[:, 2], c='blue', s=25, alpha=0.5, label='Sound Sources')\n",
    "    ax2.set_xlabel('X')\n",
    "    ax2.set_ylabel('Z')\n",
    "    ax2.set_title(f'Side view of {room_name}')\n",
    "    ax2.legend()\n",
    "    ax2.axis('equal')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = dest_path_sofa / f\"{room_name}_plots.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()  # Close the figure to free up memory\n",
    "\n",
    "    print(f\"Plots saved as {plot_path}\")\n",
    "\n",
    "    # Prepare SOFA file\n",
    "    prepare_sofa(cfg, ctx, source_positions, mic_center, mic_absolute_positions, dest_path_sofa, audio_fmts)\n",
    "    print(f\"Processing completed for {glb_file}\")\n",
    "\n",
    "\n",
    "def prepare_sofa(cfg, ctx, source_positions, mic_center, mic_absolute_positions, dest_path_sofa, audio_fmts=[\"mic\"]):\n",
    "    sr = int(cfg.sample_rate)\n",
    "    print(f\"Total number of source positions: {len(source_positions)}\")\n",
    "    room_name = os.path.splitext(glb_file.name)[0]\n",
    "    csv_filepath = dest_path_sofa / f\"{room_name}_relative_positions.csv\"\n",
    "\n",
    "    with open(csv_filepath, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['Source_Index', 'X', 'Y', 'Z'])  # Write header\n",
    "        for fmt in audio_fmts:\n",
    "            IRs = []\n",
    "            coords = []\n",
    "            max_length = 0\n",
    "            for source_index, source_position in enumerate(source_positions):\n",
    "                ir_channels = []\n",
    "                \n",
    "                # Calculate relative position using the microphone array center\n",
    "                relative_position = np.array(source_position) - mic_center\n",
    "                x, y, z = relative_position\n",
    "                x, y, z = round(x, 3), round(y, 3), round(z, 3)\n",
    "                coords.append([x, y, z])\n",
    "\n",
    "                csv_writer.writerow([source_index, x, y, z])\n",
    "                \n",
    "                max_ir_length = 0\n",
    "                for listener_index, mic_pos in enumerate(mic_absolute_positions):\n",
    "                    ir_sample_count = ctx.get_ir_sample_count(listener_index, source_index)\n",
    "                    ir_channel_count = ctx.get_ir_channel_count(listener_index, source_index)\n",
    "                    \n",
    "                    ir = np.zeros((ir_channel_count, ir_sample_count))\n",
    "                    for i in range(ir_channel_count):\n",
    "                        channel = np.array(ctx.get_ir_channel(listener_index, source_index, i))\n",
    "                        ir[i] = channel\n",
    "                    ir_channels.append(ir[0])  # mono channel for each microphone\n",
    "                    max_ir_length = max(max_ir_length, ir_sample_count)\n",
    "                \n",
    "                # Pad all IR channels to the same length\n",
    "                padded_ir_channels = []\n",
    "                for ir in ir_channels:\n",
    "                    padded_ir = np.pad(ir, (0, max_ir_length - len(ir)), mode='constant')\n",
    "                    padded_ir_channels.append(padded_ir)\n",
    "                \n",
    "                combined_ir = np.array(padded_ir_channels)\n",
    "                if combined_ir.shape[1] > max_length:\n",
    "                    max_length = combined_ir.shape[1]\n",
    "                IRs.append(combined_ir)\n",
    "                \n",
    "                print(f\"IR {source_index}:\")\n",
    "                print(f\"  Position: ({x}, {y}, {z})\")\n",
    "                print(f\"  Channels: {combined_ir.shape[0]}\")\n",
    "                print(f\"  Samples: {combined_ir.shape[1]}\")\n",
    "                print(f\"  Shape: {combined_ir.shape}\")\n",
    "            \n",
    "            # Pad IRs to max_length\n",
    "            padded_IRs = []\n",
    "            for ir in IRs:\n",
    "                if ir.shape[1] < max_length:\n",
    "                    padded = np.pad(ir, ((0, 0), (0, max_length - ir.shape[1])), mode='constant')\n",
    "                    padded_IRs.append(padded)\n",
    "                else:\n",
    "                    padded_IRs.append(ir[:, :max_length])\n",
    "            \n",
    "            filepath = dest_path_sofa / f\"soundspaces_{fmt}_{os.path.splitext(glb_file.name)[0]}.sofa\"\n",
    "            rirs = np.array(padded_IRs)\n",
    "            source_pos = np.array(coords) \n",
    "            \n",
    "            # Repeat mic_center to match the number of source positions\n",
    "            mic_pos = np.tile([0,0,0], (len(source_positions), 1))\n",
    "            \n",
    "            create_srir_sofa(\n",
    "                filepath,\n",
    "                rirs,\n",
    "                source_pos,\n",
    "                mic_pos,\n",
    "                db_name=GIBSON_DB_NAME,\n",
    "                room_name=\"soundspaces_mic_{os.path.splitext(glb_file.name)[0]}\",\n",
    "                listener_name=\"mic\",\n",
    "                sr=sr,\n",
    "            )\n",
    "    print(\"SOFA file has been created.\")\n",
    "    print(f\"Final IR array shape: {rirs.shape}\")\n",
    "          \n",
    "if __name__ == \"__main__\":\n",
    "    dataset_dir = Path(DATASET_DIR)\n",
    "    for glb_file in dataset_dir.glob(\"*.glb\"):\n",
    "        if sofa_file_exists(glb_file, dest_path_sofa, audio_fmts):\n",
    "            print(f\"Skipping {glb_file.name} - SOFA file already exists\")\n",
    "            continue\n",
    "        print(f\"Processing {glb_file.name}\")\n",
    "        prepare_soundspaces(str(glb_file), dest_path_sofa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sscaper",
   "language": "python",
   "name": "sscaper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
